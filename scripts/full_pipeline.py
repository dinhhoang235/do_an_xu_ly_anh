"""
Full Pipeline: Plate Detection â†’ Character Segmentation â†’ Recognition
"""

import cv2
import sys
import os
from pathlib import Path
import numpy as np

sys.path.append(str(Path(__file__).parent.parent))

from src.plate_detector import PlateDetector
from src.character_recognizer import CharacterRecognizer
from src.preprocessor import Preprocessor
from src.skew_corrector import SkewCorrector
import pickle

class LicensePlateRecognitionPipeline:
    def __init__(self):
        self.preprocessor = Preprocessor()
        self.plate_detector = PlateDetector()
        self.char_recognizer = CharacterRecognizer()
        self.skew_corrector = SkewCorrector()
        
        # Load hybrid model
        hybrid_model_path = Path(__file__).parent.parent / "models" / "knn_character_recognizer_hybrid.pkl"
        if hybrid_model_path.exists():
            with open(hybrid_model_path, 'rb') as f:
                data = pickle.load(f)
                self.model = data.get('model', data)
            print("âœ… Hybrid KNN model loaded")
        else:
            print(f"âŒ Model not found: {hybrid_model_path}")
            self.model = None
    
    def extract_features(self, char_img):
        """Extract features tá»« character image"""
        resized = cv2.resize(char_img, (20, 30))
        _, binary = cv2.threshold(resized, 128, 255, cv2.THRESH_BINARY_INV)
        features = binary.flatten().astype(np.float32) / 255.0
        features = np.clip(features, 0, 1)
        return features
    
    def process_image(self, image_path, visualize=True):
        """
        Pipeline hoÃ n chá»‰nh tá»«ng bÆ°á»›c:
        1. Tiá»n xá»­ lÃ½
        2. PhÃ¡t hiá»‡n biá»ƒn sá»‘
        3. Hiá»‡u chá»‰nh gÃ³c nghiÃªng
        4. Segment kÃ½ tá»±
        5. Nháº­n dáº¡ng kÃ½ tá»±
        """
        print(f"\nğŸ” Xá»­ lÃ½: {Path(image_path).name}")
        print("="*60)
        
        # Äá»c áº£nh
        image = cv2.imread(image_path)
        if image is None:
            print("âŒ KhÃ´ng thá»ƒ Ä‘á»c áº£nh")
            return None
        
        h, w = image.shape[:2]
        print(f"ğŸ“ KÃ­ch thÆ°á»›c áº£nh: {w}x{h}")
        
        # STEP 1: Tiá»n xá»­ lÃ½ áº£nh
        print("\n[Step 1] Tiá»n xá»­ lÃ½ áº£nh...")
        preprocessed = self.preprocessor.preprocess(image)
        print("  âœ… ÄÃ£ preprocess (grayscale, blur)")
        
        # STEP 2: PhÃ¡t hiá»‡n biá»ƒn sá»‘
        print("\n[Step 2] PhÃ¡t hiá»‡n biá»ƒn sá»‘...")
        plates = self.plate_detector.detect_plates(preprocessed)
        print(f"  ğŸ¯ PhÃ¡t hiá»‡n: {len(plates)} biá»ƒn sá»‘")
        
        if len(plates) == 0:
            print("  âš ï¸  KhÃ´ng phÃ¡t hiá»‡n biá»ƒn sá»‘ nÃ o")
            return None
        
        results = []
        
        # STEP 3-5: Vá»›i má»—i biá»ƒn sá»‘
        print("\n[Step 3-5] Hiá»‡u chá»‰nh gÃ³c - Segment kÃ½ tá»± - Nháº­n dáº¡ng...")
        for plate_idx, (x, y, w_plate, h_plate) in enumerate(plates, 1):
            # Crop biá»ƒn sá»‘ tá»« áº£nh gá»‘c
            plate_roi = image[y:y+h_plate, x:x+w_plate]
            
            print(f"\n  Biá»ƒn sá»‘ #{plate_idx}: ({x}, {y}) - {w_plate}x{h_plate}")
            
            # Step 3: Hiá»‡u chá»‰nh gÃ³c nghiÃªng
            corrected_roi, skew_angle = self.skew_corrector.correct_skew(plate_roi)
            if abs(skew_angle) > 0.5:
                print(f"    ğŸ”„ Hiá»‡u chá»‰nh gÃ³c: {skew_angle:.1f}Â°")
                plate_roi = corrected_roi
            else:
                print(f"    âœ… GÃ³c Ä‘Ã£ tháº³ng ({skew_angle:.1f}Â°)")
            
            # Step 4: Segment kÃ½ tá»±
            char_images = self.char_recognizer.segment_characters(plate_roi)
            
            if len(char_images) == 0:
                print(f"    âš ï¸  KhÃ´ng segment Ä‘Æ°á»£c kÃ½ tá»±")
                continue
            
            print(f"    ğŸ“‹ Segment: {len(char_images)} kÃ½ tá»±")
            
            # Nháº­n dáº¡ng
            if self.model is not None:
                features_list = [self.extract_features(char) for char in char_images]
                features_array = np.array(features_list)
                predictions = self.model.predict(features_array)
                plate_text = ''.join(predictions)
                print(f"    âœ… Káº¿t quáº£: {plate_text}")
            else:
                plate_text = "N/A"
                print(f"    âš ï¸  Model khÃ´ng sáºµn sÃ ng")
            
            results.append({
                'position': (x, y, w_plate, h_plate),
                'text': plate_text,
                'char_count': len(char_images)
            })
        
        # Visualize
        if visualize:
            result_image = image.copy()
            
            # Váº½ biá»ƒn sá»‘ bounding boxes
            for plate_idx, (x, y, w_p, h_p) in enumerate(plates, 1):
                cv2.rectangle(result_image, (x, y), (x + w_p, y + h_p), (0, 255, 0), 2)
                
                # ThÃªm text nháº­n dáº¡ng náº¿u cÃ³
                if plate_idx <= len(results):
                    plate_text = results[plate_idx - 1]['text']
                    cv2.putText(result_image, plate_text, (x, y - 5),
                               cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            cv2.imshow(f"Pipeline Result - {Path(image_path).name}", result_image)
            print("\nâ³ Nháº¥n phÃ­m báº¥t ká»³ Ä‘á»ƒ tiáº¿p tá»¥c...")
            cv2.waitKey(0)
            cv2.destroyAllWindows()
        
        print("="*60)
        return results
    
    def process_batch(self, image_dir, num_images=None):
        """Process nhiá»u áº£nh"""
        image_paths = sorted(Path(image_dir).glob("*.png"))
        if num_images:
            image_paths = image_paths[:num_images]
        
        print(f"\nğŸš€ PIPELINE HOÃ€N CHá»ˆNH")
        print(f"ğŸ“ ThÆ° má»¥c: {image_dir}")
        print(f"ğŸ“· Sá»‘ áº£nh: {len(image_paths)}\n")
        
        all_results = []
        
        for image_path in image_paths:
            results = self.process_image(str(image_path), visualize=True)
            if results:
                all_results.append({
                    'image': image_path.name,
                    'plates': results
                })
        
        # Thá»‘ng kÃª
        print(f"\n{'='*60}")
        print("ğŸ“Š THá»NG KÃŠ")
        print(f"{'='*60}")
        print(f"Tá»•ng áº£nh xá»­ lÃ½: {len(image_paths)}")
        print(f"áº¢nh phÃ¡t hiá»‡n biá»ƒn sá»‘: {len(all_results)}")
        
        if all_results:
            total_plates = sum(len(r['plates']) for r in all_results)
            total_chars = sum(sum(p['char_count'] for p in r['plates']) for r in all_results)
            print(f"Tá»•ng biá»ƒn sá»‘: {total_plates}")
            print(f"Tá»•ng kÃ½ tá»± nháº­n dáº¡ng: {total_chars}")
        
        return all_results

if __name__ == "__main__":
    pipeline = LicensePlateRecognitionPipeline()
    
    # Test folder vá»›i áº£nh cÃ³ gÃ¡n nhÃ£n
    image_dir = Path(__file__).parent.parent / "datasets" / "kaggle_foreign" / "images"
    
    results = pipeline.process_batch(str(image_dir), num_images=10)
    
    print("\nâœ… HoÃ n thÃ nh!")
