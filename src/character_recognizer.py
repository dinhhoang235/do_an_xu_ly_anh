import cv2
import numpy as np
from pathlib import Path
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle
from .preprocessor import Preprocessor

class CharacterRecognizer:
    def __init__(self):
        self.knn_model = None
        self.is_trained = False
        
        # K√≠ch th∆∞·ªõc chu·∫©n cho k√Ω t·ª±
        self.char_width = 20
        self.char_height = 30
    
    def train_knn(self, character_dataset_path, n_neighbors=5, test_size=0.2):
        print("üîÑ ƒêang t·∫£i dataset k√Ω t·ª±...")
        
        X = []  # Features
        y = []  # Labels
        
        char_path = Path(character_dataset_path)
        
        if not char_path.exists():
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {character_dataset_path}")
            return None
        
        # Duy·ªát qua t·ª´ng th∆∞ m·ª•c k√Ω t·ª±
        char_count = {}
        for char_dir in char_path.iterdir():
            if not char_dir.is_dir():
                continue
            
            char_label = char_dir.name
            char_images = list(char_dir.glob("*.png")) + list(char_dir.glob("*.jpg"))
            
            if len(char_images) == 0:
                continue
            
            char_count[char_label] = len(char_images)
            
            for img_path in char_images:
                # ƒê·ªçc ·∫£nh
                img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                
                if img is None:
                    continue
                
                # Tr√≠ch xu·∫•t features
                features = self.extract_features(img)
                
                X.append(features)
                y.append(char_label)
        
        if len(X) == 0:
            print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh k√Ω t·ª± n√†o!")
            return None
        
        X = np.array(X, dtype=np.float32)
        y = np.array(y)
        
        # Normalize X to prevent numerical issues
        X = np.clip(X, 0, 1)
        
        print(f"üìä Th·ªëng k√™ dataset:")
        print(f"   - T·ªïng s·ªë k√Ω t·ª±: {len(X)}")
        print(f"   - S·ªë lo·∫°i k√Ω t·ª±: {len(char_count)}")
        for char, count in sorted(char_count.items()):
            print(f"     {char}: {count} ·∫£nh")
        
        # Ki·ªÉm tra n·∫øu c√≥ class v·ªõi √≠t h∆°n 2 samples
        min_samples = min(char_count.values())
        use_stratify = min_samples >= 2
        
        if not use_stratify:
            print(f"\n‚ö†Ô∏è  C·∫£nh b√°o: M·ªôt s·ªë k√Ω t·ª± ch·ªâ c√≥ 1 m·∫´u, kh√¥ng th·ªÉ d√πng stratified split")
        
        # Chia train/test
        if use_stratify:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=y
            )
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
        
        print(f"\nüîÑ ƒêang hu·∫•n luy·ªán KNN v·ªõi {n_neighbors} neighbors...")
        
        # Train KNN v·ªõi weights='distance' ƒë·ªÉ gi·∫£m ·∫£nh h∆∞·ªüng c·ªßa class imbalance
        self.knn_model = KNeighborsClassifier(
            n_neighbors=n_neighbors, 
            weights='distance',  # Weighted by distance
            metric='euclidean'
        )
        self.knn_model.fit(X_train, y_train)
        self.is_trained = True
        
        # ƒê√°nh gi√° tr√™n t·∫≠p test
        y_pred = self.knn_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
        print(f"   - Accuracy tr√™n t·∫≠p test: {accuracy:.2%}")
        print(f"   - Training samples: {len(X_train)}")
        print(f"   - Test samples: {len(X_test)}")
        
        return self.knn_model
    
    def extract_features(self, char_image):
        # Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n
        resized = cv2.resize(char_image, (self.char_width, self.char_height))
        
        # Chuy·ªÉn v·ªÅ ·∫£nh nh·ªã ph√¢n
        _, binary = cv2.threshold(resized, 128, 255, cv2.THRESH_BINARY_INV)
        
        # Tr√≠ch xu·∫•t features v√† normalize
        features = binary.flatten().astype(np.float32) / 255.0  # Chu·∫©n h√≥a v·ªÅ [0, 1]
        
        # Clip ƒë·ªÉ tr√°nh numerical instability
        features = np.clip(features, 0, 1)
        
        return features
    
    def segment_characters(self, plate_image):
        # Chuy·ªÉn ·∫£nh x√°m n·∫øu c·∫ßn
        if len(plate_image.shape) == 3:
            gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)
        else:
            gray = plate_image
        
        # Adaptive thresholding
        binary = cv2.adaptiveThreshold(gray, 255, 
                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                      cv2.THRESH_BINARY_INV, 9, 15)
        
        # Morphological operations - gi·ªëng repository
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel)
        
        # T√¨m contours
        contours, _ = cv2.findContours(thre_mor, cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        # T√≠nh di·ªán t√≠ch bi·ªÉn s·ªë
        height, width = gray.shape
        roi_area = height * width
        
        # Parameters gi·ªëng repository
        Min_char = 0.005  # Optimized for foreign plates (was 0.01)
        Max_char = 0.12   # Optimized for foreign plates (was 0.09)
        
        char_data = []  # L∆∞u (x_position, char_image)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            x, y, w, h = cv2.boundingRect(contour)
            
            ratio_char = w / h
            char_area = w * h
            
            # Filter - optimized for foreign plates
            if (Min_char * roi_area < char_area < Max_char * roi_area) and \
               (0.25 < ratio_char < 0.9):
                # C·∫Øt k√Ω t·ª± t·ª´ ·∫£nh threshold
                char_img = thre_mor[y:y+h, x:x+w]
                char_data.append((x, char_img))
        
        # S·∫Øp x·∫øp theo v·ªã tr√≠ x (tr√°i sang ph·∫£i)
        char_data.sort(key=lambda item: item[0])
        
        # Ch·ªâ l·∫•y ·∫£nh k√Ω t·ª±
        sorted_chars = [char_img for _, char_img in char_data]
        
        return sorted_chars
    
    def save_model(self, filepath):
        """L∆∞u model KNN"""
        if self.is_trained:
            with open(filepath, 'wb') as f:
                pickle.dump(self.knn_model, f)
            print(f"‚úÖ ƒê√£ l∆∞u model t·∫°i: {filepath}")
    
    def load_model(self, filepath):
        """T·∫£i model KNN"""
        try:
            with open(filepath, 'rb') as f:
                self.knn_model = pickle.load(f)
            self.is_trained = True
            print(f"‚úÖ ƒê√£ t·∫£i model t·ª´: {filepath}")
        except FileNotFoundError:
            print("‚ùå Kh√¥ng t√¨m th·∫•y file model")
    
    def post_process(self, plate_text):
        if not plate_text:
            return ""
        
        # Chuy·ªÉn th√†nh ch·ªØ hoa
        plate_text = plate_text.upper().strip()
        
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng
        plate_text = plate_text.replace(" ", "")
        
        # Thay th·∫ø k√Ω t·ª± nh·∫ßm l·∫´n th∆∞·ªùng g·∫∑p
        replacements = {
            'O': '0',  # Letter O ‚Üí Number 0 (n·∫øu l√† s·ªë)
            'I': '1',  # Letter I ‚Üí Number 1 (n·∫øu l√† s·ªë)
            'Z': '2',  # Letter Z ‚Üí Number 2 (n·∫øu l√† s·ªë)
            'S': '5',  # Letter S ‚Üí Number 5 (n·∫øu l√† s·ªë)
        }
        
        # Ch·ªâ thay th·∫ø n·∫øu ·ªü v·ªã tr√≠ s·ªë
        for old_char, new_char in replacements.items():
            plate_text = plate_text.replace(old_char, new_char)
        
        return plate_text