import cv2
import numpy as np
import os
from pathlib import Path
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import pickle
from .preprocessor import Preprocessor

class CharacterRecognizer:
    def __init__(self):
        self.knn_model = None
        self.is_trained = False
        
        # K√≠ch th∆∞·ªõc chu·∫©n cho k√Ω t·ª±
        self.char_width = 20
        self.char_height = 30
        
    def load_knn_from_files(self, classifications_file="classifications.txt", 
                            flattened_images_file="flattened_images.txt"):
        """
        Load KNN model t·ª´ file gi·ªëng repository VIETNAMESE_LICENSE_PLATE
        """
        print("üîÑ ƒêang load KNN model t·ª´ file...")
        
        if not Path(classifications_file).exists():
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y {classifications_file}")
            return False
        
        if not Path(flattened_images_file).exists():
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y {flattened_images_file}")
            return False
        
        # Load data
        classifications = np.loadtxt(classifications_file, np.float32)
        flattened_images = np.loadtxt(flattened_images_file, np.float32)
        
        # Reshape classifications
        classifications = classifications.reshape((classifications.size, 1))
        
        # T·∫°o KNN model
        self.knn_model = cv2.ml.KNearest_create()
        self.knn_model.train(flattened_images, cv2.ml.ROW_SAMPLE, classifications)
        
        self.is_trained = True
        
        print(f"‚úÖ ƒê√£ load KNN model")
        print(f"   - S·ªë l∆∞·ª£ng m·∫´u: {flattened_images.shape[0]}")
        print(f"   - Feature dimension: {flattened_images.shape[1]}")
        
        return True
        
    def create_template_dataset(self, vn_plates_folder):
        """
        T·∫°o b·ªô template t·ª´ 22 ·∫£nh Vi·ªát Nam
        """
        print("üîÑ ƒêang t·∫°o b·ªô template k√Ω t·ª±...")
        
        # K√Ω t·ª± c·∫ßn nh·∫≠n d·∫°ng (bi·ªÉn s·ªë VN)
        chars = "0123456789ABCDEFGHKLMNPRSTUVXYZ"
        
        # T·∫°o th∆∞ m·ª•c template n·∫øu ch∆∞a c√≥
        template_dir = "datasets/character_templates"
        os.makedirs(template_dir, exist_ok=True)
        
        # Dictionary l∆∞u template
        templates = {}
        
        # V·ªõi m·ªói k√Ω t·ª±, t·∫°o template ƒë∆°n gi·∫£n (c√≥ th·ªÉ thay b·∫±ng ·∫£nh th·∫≠t sau)
        for char in chars:
            # T·∫°o ·∫£nh tr·∫Øng
            template = np.ones((self.char_height, self.char_width), dtype=np.uint8) * 255
            
            # V·∫Ω k√Ω t·ª± l√™n ·∫£nh (gi·∫£ l·∫≠p - th·ª±c t·∫ø s·∫Ω d√πng ·∫£nh th·∫≠t t·ª´ dataset)
            font = cv2.FONT_HERSHEY_SIMPLEX
            font_scale = 0.8
            thickness = 2
            
            # T√≠nh to√°n v·ªã tr√≠ ƒë·ªÉ cƒÉn gi·ªØa
            text_size = cv2.getTextSize(char, font, font_scale, thickness)[0]
            text_x = (self.char_width - text_size[0]) // 2
            text_y = (self.char_height + text_size[1]) // 2
            
            # V·∫Ω k√Ω t·ª± m√†u ƒëen
            cv2.putText(template, char, (text_x, text_y), font, font_scale, 0, thickness)
            
            templates[char] = template
            
            # L∆∞u template ra file
            cv2.imwrite(f"{template_dir}/{char}.png", template)
        
        self.char_templates = templates
        print(f"‚úÖ ƒê√£ t·∫°o {len(templates)} template k√Ω t·ª±")
        
        return templates
    
    def train_knn(self, character_dataset_path, n_neighbors=5, test_size=0.2):
        """
        Hu·∫•n luy·ªán m√¥ h√¨nh KNN t·ª´ dataset k√Ω t·ª± ƒë√£ c·∫Øt
        
        Args:
            character_dataset_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn th∆∞ m·ª•c ch·ª©a c√°c k√Ω t·ª± ƒë√£ ph√¢n lo·∫°i
            n_neighbors: S·ªë l∆∞·ª£ng neighbors cho KNN
            test_size: T·ª∑ l·ªá d·ªØ li·ªáu test
        """
        print("üîÑ ƒêang t·∫£i dataset k√Ω t·ª±...")
        
        X = []  # Features
        y = []  # Labels
        
        char_path = Path(character_dataset_path)
        
        if not char_path.exists():
            print(f"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c: {character_dataset_path}")
            return None
        
        # Duy·ªát qua t·ª´ng th∆∞ m·ª•c k√Ω t·ª±
        char_count = {}
        for char_dir in char_path.iterdir():
            if not char_dir.is_dir():
                continue
            
            char_label = char_dir.name
            char_images = list(char_dir.glob("*.png")) + list(char_dir.glob("*.jpg"))
            
            if len(char_images) == 0:
                continue
            
            char_count[char_label] = len(char_images)
            
            for img_path in char_images:
                # ƒê·ªçc ·∫£nh
                img = cv2.imread(str(img_path), cv2.IMREAD_GRAYSCALE)
                
                if img is None:
                    continue
                
                # Tr√≠ch xu·∫•t features
                features = self.extract_features(img)
                
                X.append(features)
                y.append(char_label)
        
        if len(X) == 0:
            print("‚ùå Kh√¥ng t√¨m th·∫•y ·∫£nh k√Ω t·ª± n√†o!")
            return None
        
        X = np.array(X, dtype=np.float32)
        y = np.array(y)
        
        # Normalize X to prevent numerical issues
        X = np.clip(X, 0, 1)
        
        print(f"üìä Th·ªëng k√™ dataset:")
        print(f"   - T·ªïng s·ªë k√Ω t·ª±: {len(X)}")
        print(f"   - S·ªë lo·∫°i k√Ω t·ª±: {len(char_count)}")
        for char, count in sorted(char_count.items()):
            print(f"     {char}: {count} ·∫£nh")
        
        # Ki·ªÉm tra n·∫øu c√≥ class v·ªõi √≠t h∆°n 2 samples
        min_samples = min(char_count.values())
        use_stratify = min_samples >= 2
        
        if not use_stratify:
            print(f"\n‚ö†Ô∏è  C·∫£nh b√°o: M·ªôt s·ªë k√Ω t·ª± ch·ªâ c√≥ 1 m·∫´u, kh√¥ng th·ªÉ d√πng stratified split")
        
        # Chia train/test
        if use_stratify:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=y
            )
        else:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42
            )
        
        print(f"\nüîÑ ƒêang hu·∫•n luy·ªán KNN v·ªõi {n_neighbors} neighbors...")
        
        # Train KNN v·ªõi weights='distance' ƒë·ªÉ gi·∫£m ·∫£nh h∆∞·ªüng c·ªßa class imbalance
        self.knn_model = KNeighborsClassifier(
            n_neighbors=n_neighbors, 
            weights='distance',  # Weighted by distance
            metric='euclidean'
        )
        self.knn_model.fit(X_train, y_train)
        self.is_trained = True
        
        # ƒê√°nh gi√° tr√™n t·∫≠p test
        y_pred = self.knn_model.predict(X_test)
        accuracy = accuracy_score(y_test, y_pred)
        
        print(f"‚úÖ Hu·∫•n luy·ªán ho√†n t·∫•t!")
        print(f"   - Accuracy tr√™n t·∫≠p test: {accuracy:.2%}")
        print(f"   - Training samples: {len(X_train)}")
        print(f"   - Test samples: {len(X_test)}")
        
        return self.knn_model
    
    def extract_features(self, char_image):
        """
        Tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ ·∫£nh k√Ω t·ª±
        """
        # Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n
        resized = cv2.resize(char_image, (self.char_width, self.char_height))
        
        # Chuy·ªÉn v·ªÅ ·∫£nh nh·ªã ph√¢n
        _, binary = cv2.threshold(resized, 128, 255, cv2.THRESH_BINARY_INV)
        
        # Tr√≠ch xu·∫•t features v√† normalize
        features = binary.flatten().astype(np.float32) / 255.0  # Chu·∫©n h√≥a v·ªÅ [0, 1]
        
        # Clip ƒë·ªÉ tr√°nh numerical instability
        features = np.clip(features, 0, 1)
        
        return features
    
    def segment_characters(self, plate_image):
        """
        Ph√¢n t√°ch k√Ω t·ª± t·ª´ ·∫£nh bi·ªÉn s·ªë - gi·ªëng VIETNAMESE_LICENSE_PLATE
        """
        # Chuy·ªÉn ·∫£nh x√°m n·∫øu c·∫ßn
        if len(plate_image.shape) == 3:
            gray = cv2.cvtColor(plate_image, cv2.COLOR_BGR2GRAY)
        else:
            gray = plate_image
        
        # Adaptive thresholding
        binary = cv2.adaptiveThreshold(gray, 255, 
                                      cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                      cv2.THRESH_BINARY_INV, 9, 15)
        
        # Morphological operations - gi·ªëng repository
        kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3, 3))
        thre_mor = cv2.morphologyEx(binary, cv2.MORPH_DILATE, kernel)
        
        # T√¨m contours
        contours, _ = cv2.findContours(thre_mor, cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        # T√≠nh di·ªán t√≠ch bi·ªÉn s·ªë
        height, width = gray.shape
        roi_area = height * width
        
        # Parameters gi·ªëng repository
        Min_char = 0.005  # Optimized for foreign plates (was 0.01)
        Max_char = 0.12   # Optimized for foreign plates (was 0.09)
        
        char_data = []  # L∆∞u (x_position, char_image)
        
        for contour in contours:
            area = cv2.contourArea(contour)
            x, y, w, h = cv2.boundingRect(contour)
            
            ratio_char = w / h
            char_area = w * h
            
            # Filter - optimized for foreign plates
            if (Min_char * roi_area < char_area < Max_char * roi_area) and \
               (0.25 < ratio_char < 0.9):
                # C·∫Øt k√Ω t·ª± t·ª´ ·∫£nh threshold
                char_img = thre_mor[y:y+h, x:x+w]
                char_data.append((x, char_img))
        
        # S·∫Øp x·∫øp theo v·ªã tr√≠ x (tr√°i sang ph·∫£i)
        char_data.sort(key=lambda item: item[0])
        
        # Ch·ªâ l·∫•y ·∫£nh k√Ω t·ª±
        sorted_chars = [char_img for _, char_img in char_data]
        
        return sorted_chars
    
    def segment_characters_improved(self, plate_image):
        """
        Ph√¢n t√°ch k√Ω t·ª± c·∫£i ti·∫øn - d√πng Preprocessor pipeline
        """
        preprocessor = Preprocessor()
        
        # Preprocess v·ªõi Canny + Morphology
        _, processed = preprocessor.preprocess(plate_image)
        
        # T√¨m contours
        contours, _ = cv2.findContours(processed, cv2.RETR_EXTERNAL, 
                                       cv2.CHAIN_APPROX_SIMPLE)
        
        # L·∫•y k√≠ch th∆∞·ªõc ƒë·ªÉ t√≠nh di·ªán t√≠ch
        height, width = processed.shape
        roi_area = height * width
        
        # Parameters t·ªëi ∆∞u
        Min_char = 0.003
        Max_char = 0.15
        
        char_data = []
        
        for contour in contours:
            area = cv2.contourArea(contour)
            x, y, w, h = cv2.boundingRect(contour)
            
            if h == 0:
                continue
            
            ratio_char = w / h
            char_area = w * h
            
            # Filter
            if (Min_char * roi_area < char_area < Max_char * roi_area) and \
               (0.15 < ratio_char < 0.9):
                # C·∫Øt t·ª´ ·∫£nh processed
                char_img = processed[y:y+h, x:x+w]
                char_data.append((x, char_img))
        
        # S·∫Øp x·∫øp theo v·ªã tr√≠ x
        char_data.sort(key=lambda item: item[0])
        sorted_chars = [char_img for _, char_img in char_data]
        
        return sorted_chars
    
    def recognize_template_matching(self, char_image):
        """
        Nh·∫≠n d·∫°ng k√Ω t·ª± s·ª≠ d·ª•ng Template Matching
        """
        best_char = '?'
        best_score = -1
        
        # Resize k√Ω t·ª± ƒë·∫ßu v√†o
        resized_char = cv2.resize(char_image, (self.char_width, self.char_height))
        
        for char, template in self.char_templates.items():
            # Template matching
            result = cv2.matchTemplate(resized_char, template, cv2.TM_CCOEFF_NORMED)
            score = cv2.minMaxLoc(result)[1]  # L·∫•y ƒëi·ªÉm s·ªë t·ªët nh·∫•t
            
            if score > best_score:
                best_score = score
                best_char = char
        
        return best_char, best_score
    
    def recognize_knn(self, char_image):
        """
        Nh·∫≠n d·∫°ng k√Ω t·ª± s·ª≠ d·ª•ng KNN (OpenCV style nh∆∞ VIETNAMESE_LICENSE_PLATE)
        """
        if not self.is_trained:
            return '?', 0.0
        
        # Resize v·ªÅ k√≠ch th∆∞·ªõc chu·∫©n
        char_resized = cv2.resize(char_image, (self.char_width, self.char_height))
        
        # Chuy·ªÉn sang grayscale n·∫øu c·∫ßn
        if len(char_resized.shape) == 3:
            char_resized = cv2.cvtColor(char_resized, cv2.COLOR_BGR2GRAY)
        
        # Flatten th√†nh 1D array v√† normalize
        char_flattened = char_resized.flatten().astype(np.float32) / 255.0
        char_flattened = np.clip(char_flattened, 0, 1).reshape(1, -1)
        
        # Predict v·ªõi sklearn KNN
        try:
            probabilities = self.knn_model.predict_proba(char_flattened)[0]
            predicted_label = self.knn_model.predict(char_flattened)[0]
            
            # L·∫•y confidence (x√°c su·∫•t cao nh·∫•t)
            confidence = np.max(probabilities)
            
            predicted_char = predicted_label
        except Exception as e:
            # Fallback n·∫øu c√≥ l·ªói
            predicted_char = '?'
            confidence = 0.0
        
        return predicted_char, confidence
    
    def recognize_plate(self, plate_image, method='template'):
        """
        Nh·∫≠n d·∫°ng to√†n b·ªô bi·ªÉn s·ªë
        """
        # Ph√¢n t√°ch k√Ω t·ª±
        characters = self.segment_characters(plate_image)
        
        if not characters:
            return "", []
        
        plate_text = ""
        recognition_results = []
        
        for i, char_img in enumerate(characters):
            if method == 'knn' and self.is_trained:
                char, confidence = self.recognize_knn(char_img)
            else:
                char, confidence = self.recognize_template_matching(char_img)
            
            plate_text += char
            recognition_results.append((char, confidence))
        
        return plate_text, recognition_results
    
    def save_model(self, filepath):
        """L∆∞u model KNN"""
        if self.is_trained:
            with open(filepath, 'wb') as f:
                pickle.dump(self.knn_model, f)
            print(f"‚úÖ ƒê√£ l∆∞u model t·∫°i: {filepath}")
    
    def load_model(self, filepath):
        """T·∫£i model KNN"""
        try:
            with open(filepath, 'rb') as f:
                self.knn_model = pickle.load(f)
            self.is_trained = True
            print(f"‚úÖ ƒê√£ t·∫£i model t·ª´: {filepath}")
        except FileNotFoundError:
            print("‚ùå Kh√¥ng t√¨m th·∫•y file model")
    
    def validate_plate_format(self, plate_text):
        """
        Ki·ªÉm tra t√≠nh h·ª£p l·ªá c·ªßa bi·ªÉn s·ªë
        H·ªó tr·ª£ bi·ªÉn s·ªë Vi·ªát Nam v√† n∆∞·ªõc ngo√†i
        """
        if not plate_text or len(plate_text.strip()) == 0:
            return False, "Bi·ªÉn s·ªë tr·ªëng"
        
        plate_text = plate_text.upper().strip()
        
        # Lo·∫°i b·ªè k√Ω t·ª± kh√¥ng h·ª£p l·ªá
        valid_chars = "0123456789ABCDEFGHKLMNPRSTUVXYZ-"
        
        # Ki·ªÉm tra k√Ω t·ª±
        for char in plate_text:
            if char not in valid_chars:
                return False, f"K√Ω t·ª± '{char}' kh√¥ng h·ª£p l·ªá"
        
        # Ki·ªÉm tra ƒë·ªô d√†i (bi·ªÉn s·ªë th∆∞·ªùng 6-10 k√Ω t·ª±)
        if len(plate_text) < 6 or len(plate_text) > 10:
            return False, f"ƒê·ªô d√†i bi·ªÉn s·ªë kh√¥ng h·ª£p l·ªá: {len(plate_text)}"
        
        # N·∫øu c√≥ d·∫•u g·∫°ch ngang, ki·ªÉm tra v·ªã tr√≠
        if '-' in plate_text:
            # Format: XXX-YYYY ho·∫∑c XXXX-YY
            parts = plate_text.split('-')
            if len(parts) != 2:
                return False, "ƒê·ªãnh d·∫°ng d·∫•u g·∫°ch ngang kh√¥ng h·ª£p l·ªá"
        
        return True, "H·ª£p l·ªá"
    
    def post_process(self, plate_text):
        """
        H·∫≠u x·ª≠ l√Ω k·∫øt qu·∫£ nh·∫≠n d·∫°ng
        - Lo·∫°i b·ªè k√Ω t·ª± nhi·ªÖu
        - Chu·∫©n h√≥a ƒë·ªãnh d·∫°ng
        """
        if not plate_text:
            return ""
        
        # Chuy·ªÉn th√†nh ch·ªØ hoa
        plate_text = plate_text.upper().strip()
        
        # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng
        plate_text = plate_text.replace(" ", "")
        
        # Thay th·∫ø k√Ω t·ª± nh·∫ßm l·∫´n th∆∞·ªùng g·∫∑p
        replacements = {
            'O': '0',  # Letter O ‚Üí Number 0 (n·∫øu l√† s·ªë)
            'I': '1',  # Letter I ‚Üí Number 1 (n·∫øu l√† s·ªë)
            'Z': '2',  # Letter Z ‚Üí Number 2 (n·∫øu l√† s·ªë)
            'S': '5',  # Letter S ‚Üí Number 5 (n·∫øu l√† s·ªë)
        }
        
        # Ch·ªâ thay th·∫ø n·∫øu ·ªü v·ªã tr√≠ s·ªë
        for old_char, new_char in replacements.items():
            plate_text = plate_text.replace(old_char, new_char)
        
        return plate_text